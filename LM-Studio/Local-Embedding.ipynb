{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368632a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center> <h1>Local Embeddings on CPU with LM Studio</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c331cfbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Install langchain-openai & langchain-qdrant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c5a23ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Using cached langchain_openai-0.1.23-py3-none-any.whl (51 kB)\n",
      "Collecting langchain-qdrant\n",
      "  Using cached langchain_qdrant-0.1.3-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.35 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-openai) (0.2.38)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-openai) (1.42.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-qdrant) (2.8.2)\n",
      "Requirement already satisfied: qdrant-client<2.0.0,>=1.10.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-qdrant) (1.11.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (0.1.100)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (24.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.5)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (3.5.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-qdrant) (2.20.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-qdrant) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (1.26.20)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (1.66.1)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (1.26.4)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (1.66.1)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (2.10.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.28.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (63.4.1)\n",
      "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (5.28.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (2022.9.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (4.1.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.35->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.35->langchain-openai) (3.10.7)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from portalocker<3.0.0,>=2.7.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (302)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.40.0->langchain-openai) (0.4.5)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from h2<5,>=3->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (4.0.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from h2<5,>=3->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (6.0.1)\n",
      "Installing collected packages: langchain-qdrant, langchain-openai\n",
      "Successfully installed langchain-openai-0.1.23 langchain-qdrant-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-openai langchain-qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fa81e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Instanciate an OpenAIEmbeddings object with the LM Studio base url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea45f07",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 Local URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "676c2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "model = OpenAIEmbeddings(\n",
    "    openai_api_base=\"http://localhost:1234/v1\", \n",
    "    api_key=\"type-anything-here\", \n",
    "    check_embedding_ctx_length=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a788a81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "query = \"this is my first lm studio embedding input\"\n",
    "vector = model.embed_query(query)\n",
    "print(len(vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2bd230",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 Public URL (e.g. for colab users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044336aa",
   "metadata": {},
   "source": [
    "As colab raises a Connection Error when calling a \"localhost\" endpoint, you can turn it into a public url with [Ngrok](https://ngrok.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb15e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bis = OpenAIEmbeddings(\n",
    "    openai_api_base=\"https://3646-46-193-69-6.ngrok-free.app/v1\", \n",
    "    api_key=\"type-anything-here\", \n",
    "    check_embedding_ctx_length=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb22d857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "vector_bis = model_bis.embed_query(query)\n",
    "print(vector==vector_bis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f4bbab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Create a [Qdrant](https://qdrant.tech/#) collection for your Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "694a0bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "client = QdrantClient(path=\"/tmp/tutorials\")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"embedding_tutorial\",\n",
    "    vectors_config=VectorParams(size=768, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6373bf9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Embed & upsert documents to the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147f75fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"search_document: I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "        metadata={\"source\": \"tweet\"},\n",
    "        id=1,\n",
    "    ),\n",
    "     Document(\n",
    "        page_content=\"search_document: The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "        metadata={\"source\": \"news\"},\n",
    "        id=2,\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"search_document: Building an exciting new project with LangChain - come check it out!\",\n",
    "        metadata={\"source\": \"tweet\"},\n",
    "        id=3,\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"search_document: Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "        metadata={\"source\": \"news\"},\n",
    "        id=4,\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"search_document: Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "        metadata={\"source\": \"tweet\"},\n",
    "        id=5,\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"search_document: Is the new iPhone worth the price? Read this review to find out.\",\n",
    "        metadata={\"source\": \"website\"},\n",
    "        id=6,\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"search_document: The top 10 soccer players in the world right now.\",\n",
    "        metadata={\"source\": \"website\"},\n",
    "        id=7,\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"search_document: LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "        metadata={\"source\": \"tweet\"},\n",
    "        id=8,\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"search_document: The stock market is down 500 points today due to fears of a recession.\",\n",
    "        metadata={\"source\": \"news\"},\n",
    "        id=9,\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"search_document: I have a bad feeling I am going to get deleted :(\",\n",
    "        metadata={\"source\": \"tweet\"},\n",
    "        id=10,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99598d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore, RetrievalMode\n",
    "\n",
    "qdrant = QdrantVectorStore.from_documents(\n",
    "    documents,\n",
    "    embedding=model,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"embedding_tutorial\",\n",
    "    retrieval_mode=RetrievalMode.DENSE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ba87a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Perform similarity search with metadata filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3befc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http import models\n",
    "\n",
    "def retrieve(query, top_k, filt):\n",
    "    key, value = filt.split(\"==\")\n",
    "    results = qdrant.similarity_search_with_score(\n",
    "        f\"search_query: {query}\", k=top_k, filter=models.Filter(\n",
    "            should=[\n",
    "                models.FieldCondition(\n",
    "                    key=key,\n",
    "                    match=models.MatchValue(\n",
    "                        value=value\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    for res, score in results:\n",
    "        print(f\"*Text: {res.page_content[17:]}\\n Source: {res.metadata['source']}\\n Score: {score}\\n\\n\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5204c2a-33d3-40cc-aa42-3264c68bfa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Text: Wow! That was an amazing movie. I can't wait to see it again.\n",
      " Source: tweet\n",
      " Score: 0.37506646278842126\n",
      "\n",
      "\n",
      "*Text: LangGraph is the best framework for building stateful, agentic applications!\n",
      " Source: tweet\n",
      " Score: 0.3251572418324922\n",
      "\n",
      "\n",
      "*Text: I have a bad feeling I am going to get deleted :(\n",
      " Source: tweet\n",
      " Score: 0.2657674549552088\n",
      "\n",
      "\n",
      "*Text: I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\n",
      " Source: tweet\n",
      " Score: 0.2270696175199384\n",
      "\n",
      "\n",
      "*Text: Building an exciting new project with LangChain - come check it out!\n",
      " Source: tweet\n",
      " Score: 0.15759966780919388\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = retrieve(query=\"what did you think about the movie ?\", top_k=5, filt=\"metadata.source==tweet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
